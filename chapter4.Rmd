---
title: chapter 4
output: html_document
date: "2022-11-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the boston data and checking the structure

Load the Boston data from the MASS package. Explore the structure and the dimensions of the data and

```{r}
library(MASS)

# load the data
data("Boston")

# explore the dataset
str(Boston)
summary(Boston)
dim(Boston)
```


Dataset has 506 observations and 14 variables. All variables are numerical and each one describes housing values in Boston. More info on the variables can be found from [here](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html). 


## Graphical overview of the data

```{r}
pairplot <- pairs(Boston)
pairplot
```

```{r}
cor_matrix <- cor(Boston) 
cor_matrix <- round(cor_matrix, digits = 2)

# rounded correlation matrix
cor_matrix

# visualize the correlation matrix
library(corrplot)
corrplot(cor_matrix, method="circle")

```

Describe and interpret the outputs, commenting on the distributions of the variables and the relationships between them. (0-2 points)

## Standardize the dataset and print out summaries of the scaled data
Scaling means that the column means are first subtracted from the columns and then divided by the standard deviation. Scaling will shift the mean to 0 as we can see here. 

```{r}
boston_scaled <- scale(Boston)
summary(boston_scaled)
summary(Boston)
# change into a data frame for future use
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)

```
## Turn crime rate into categorical variable use quantiles as the break points, replace the old crime rate with the new one. 

```{r}

summary(boston_scaled$crim)

# creating a quantile vector
bins <- quantile(boston_scaled$crim)
bins

# next a categorical variable
labelsadd <- c("low", "med_low", "med_high", "high")
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = labelsadd)
# how does it look like?
table(crime)

# Replacing the old crim with the new catergorical crim
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)


```

## Divide the dataset into train and test sets (80% to the train set)

```{r}
# number of rows
nrow(boston_scaled)
n <- 506

# randomly select 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create the train set
train <- boston_scaled[ind,]

# and the test set
test <- boston_scaled[-ind,]

# correct classes from the test data 
correct_classes <- test$crime

# remove the crime variable from test data
test <- dplyr::select(test, -crime)

```


## Fit the linear discriminant analysis on the train set using the categorical crime rate as the target and all other variables as predictors. Draw the LDA plot. 

```{r}
library(MASS)

# linear discriminant analysis
lda.fit <- lda(crime ~., data = train)
lda.fit

# biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# LDA plot
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 2)
```
##  Predict the classes with the LDA model on the test data and cross tabulate the results with crime categories from the test set. 

Crime categories have already been saved from the test set and categorical crime variable has been removed from the test dataset. 

```{r}

# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)


```
Comment on the results. (0-3 points)

## Reload and standardize the Boston dataset
```{r}
data("Boston")
dim(Boston)

boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)
boston_scaled <- as.data.frame(boston_scaled)
```

## Calculate the distances between the observations.

```{r}
# euclidean distance matrix
dist_eu <- dist(boston_scaled)

# look at the summary of the distances
summary(dist_eu)

```

## Run k-means algorithm on the dataset. 
```{r}

```

Investigate what is the optimal number of clusters and run the algorithm again. Visualize the clusters (for example with the pairs() or ggpairs() functions, where the clusters are separated with colors) and interpret the results. (0-4 points)

```{r}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
